{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M5_LGB_WRMSSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoRUB6tdOvRExaQthIyLp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdwang1808/M5_LGB_WRMSSE/blob/master/M5_LGB_WRMSSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvzqbkpkfHxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "34df544b-b81a-4f58-f5e9-580f6fbb0139"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.21-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.21-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.21-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY3mFufNfVQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "import os\n",
        "import sys\n",
        "os.chdir('drive/Colab Notebooks/M5_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frKJDiL2h5nL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e4a0cdac-1e8f-4d58-adc1-5d7d9d541e80"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import lightgbm as lgb\n",
        "# import graphviz\n",
        "from  datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Syevh3r99d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 减少内存占用空间\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics: \n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_M-DVVOsJFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train data_sale \n",
        "train_start = 1\n",
        "test_start = 1800\n",
        "is_train = True\n",
        "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float16\" }\n",
        "CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
        "      \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int8\",\n",
        "      \"month\": \"int8\", \"year\": \"int16\", \"snap_CA\": \"int8\", 'snap_TX': 'int8', 'snap_WI': 'int8' }\n",
        "\n",
        "start_day = train_start if is_train else test_start\n",
        "numcols = [f\"d_{day}\" for day in range(start_day,1914)]\n",
        "catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
        "SALE_DTYPES = {numcol:\"float32\" for numcol in numcols} \n",
        "SALE_DTYPES.update({col: \"category\" for col in catcols if col != \"id\"})\n",
        "\n",
        "price = pd.read_csv('sell_prices.csv',dtype=PRICE_DTYPES)\n",
        "cal = pd.read_csv('calendar.csv',dtype=CAL_DTYPES)\n",
        "sale = pd.read_csv('sales_train_validation.csv',dtype=SALE_DTYPES,usecols=catcols+numcols) #读取指定列\n",
        "    \n",
        "# 类别标签转换\n",
        "for col, col_dtype in PRICE_DTYPES.items():\n",
        "  if col_dtype == \"category\":\n",
        "    price[col] = price[col].cat.codes.astype(\"int16\")\n",
        "    price[col] -= price[col].min()\n",
        "\n",
        "cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
        "for col, col_dtype in CAL_DTYPES.items():\n",
        "  if col_dtype == \"category\":\n",
        "    cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
        "    cal[col] -= cal[col].min()\n",
        "\n",
        "for col in catcols:\n",
        "  if col != \"id\":\n",
        "    sale[col] = sale[col].cat.codes.astype(\"int16\")\n",
        "    sale[col] -= sale[col].min()\n",
        "\n",
        "# 提交格式里有一部分为空\n",
        "if not is_train:\n",
        "  for day in range(1913+1, 1913+ 2*28 +1):\n",
        "    sale[f\"d_{day}\"] = np.nan\n",
        "\n",
        "sale = pd.melt(sale,\n",
        "        id_vars = catcols,\n",
        "        value_vars = [col for col in sale.columns if col.startswith(\"d_\")],\n",
        "        var_name = \"d\",\n",
        "        value_name = \"sales\")\n",
        "sale = reduce_mem_usage(sale)\n",
        "sale = sale.merge(cal, on= \"d\", copy = False)\n",
        "sale = sale.merge(price, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
        "sale.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oFdctndtalB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_feature(sale, is_train=True, day=None):\n",
        "    # 加入特征\n",
        "    lags = [7, 28]\n",
        "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
        "\n",
        "    # 如果是测试集只需要计算一天的特征，减少计算量\n",
        "    # 注意训练集和测试集特征生成要一致\n",
        "    if is_train:\n",
        "        for lag, lag_col in zip(lags, lag_cols):\n",
        "            sale[lag_col] = sale[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
        "    else:\n",
        "        for lag, lag_col in zip(lags, lag_cols):\n",
        "            sale.loc[sale.date == day, lag_col] = sale.loc[sale.date ==day-timedelta(days=lag), 'sales'].values  \n",
        "\n",
        "\n",
        "    # 取7天前的数据，28天前的数据做移动平均\n",
        "    wins = [7, 28]\n",
        "\n",
        "    if is_train:\n",
        "        for win in wins :\n",
        "            for lag,lag_col in zip(lags, lag_cols):\n",
        "                sale[f\"rmean_{lag}_{win}\"] = sale[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
        "    else:\n",
        "        for win in wins:\n",
        "            for lag in lags:\n",
        "                df_window = sale[(sale.date <= day-timedelta(days=lag)) & (sale.date > day-timedelta(days=lag+win))]\n",
        "                df_window_grouped = df_window.groupby(\"id\").agg({'sales':'mean'}).reindex(sale.loc[sale.date==day,'id'])\n",
        "                sale.loc[sale.date == day,f\"rmean_{lag}_{win}\"] = df_window_grouped.sales.values   \n",
        "\n",
        "    # 处理时间特征\n",
        "    date_features = {\"wday\": \"weekday\",\n",
        "            \"week\": \"weekofyear\",\n",
        "            \"month\": \"month\",\n",
        "            \"quarter\": \"quarter\",\n",
        "            \"year\": \"year\",\n",
        "            \"mday\": \"day\"}\n",
        "    for date_feat_name, date_feat_func in date_features.items():\n",
        "        if date_feat_name in sale.columns:\n",
        "            sale[date_feat_name] = sale[date_feat_name].astype(\"int16\")\n",
        "        else:\n",
        "            sale[date_feat_name] = getattr(sale[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
        "    return sale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh6tJMhMvRSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create feature_sale\n",
        "is_train=True\n",
        "day=None\n",
        "lags = [7, 28]\n",
        "lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
        "\n",
        "# 如果是测试集只需要计算一天的特征，减少计算量\n",
        "# 注意训练集和测试集特征生成要一致\n",
        "if is_train:\n",
        "  for lag, lag_col in zip(lags, lag_cols):\n",
        "    sale[lag_col] = sale[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
        "else:\n",
        "  for lag, lag_col in zip(lags, lag_cols):\n",
        "    sale.loc[sale.date == day, lag_col] = sale.loc[sale.date ==day-timedelta(days=lag), 'sales'].values  \n",
        "\n",
        "# 将获取7天前的数据，28天前的数据做移动平均\n",
        "wins = [7, 28]\n",
        "if is_train:\n",
        "  for win in wins :\n",
        "    for lag,lag_col in zip(lags, lag_cols):\n",
        "      sale[f\"rmean_{lag}_{win}\"] = sale[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
        "else:\n",
        "  for win in wins:\n",
        "    for lag in lags:\n",
        "      df_window = sale[(sale.date <= day-timedelta(days=lag)) & (sale.date > day-timedelta(days=lag+win))]\n",
        "      df_window_grouped = df_window.groupby(\"id\").agg({'sales':'mean'}).reindex(sale.loc[sale.date==day,'id'])\n",
        "      sale.loc[sale.date == day,f\"rmean_{lag}_{win}\"] = df_window_grouped.sales.values   \n",
        "\n",
        "# 处理时间特征\n",
        "# 有的时间特征没有，通过datetime的方法自动生成\n",
        "date_features = {\"wday\": \"weekday\",\n",
        "         \"week\": \"weekofyear\",\n",
        "         \"month\": \"month\",\n",
        "         \"quarter\": \"quarter\",\n",
        "         \"year\": \"year\",\n",
        "         \"mday\": \"day\"}\n",
        "for date_feat_name, date_feat_func in date_features.items():\n",
        "  if date_feat_name in sale.columns:\n",
        "    sale[date_feat_name] = sale[date_feat_name].astype(\"int16\")\n",
        "  else:\n",
        "    sale[date_feat_name] = getattr(sale[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
        "sale.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBDG449azPSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/chrisrichardmiles/m5-flexible-custom-metric-lv-12-only-for-lgbm\n",
        "# 根据Level_12自定义损失函数(待修改)\n",
        "def L12_WRMSSE(preds, actuals, p_horizon, num_products, scale, weight): \n",
        "    \n",
        "    actuals = actuals[-(p_horizon * num_products):]\n",
        "    preds = preds[-(p_horizon * num_products):]\n",
        "    diff = actuals - preds\n",
        "    res = diff ** 2\n",
        "    res = res/scale.values\n",
        "    res = res\n",
        "    res = res.reshape(p_horizon, num_products)\n",
        "    res = res.mean(axis=0)\n",
        "    res = np.sqrt(res)\n",
        "    res = res * weight\n",
        "    res = res.sum()\n",
        "    return res\n",
        "\n",
        "def get_weights_scales_level_12(df, end_test, path):\n",
        "  \n",
        "    wdf = pd.read_csv(f'{path}weight_scale_{end_test-27}.csv')\n",
        "    wdf['scaled_weight'] = wdf.weight/np.sqrt(wdf.scale)\n",
        "    wdf = wdf[wdf.Level_id == 'Level12']\n",
        "    wdf['id'] = wdf['Agg_Level_1'] + '_' +  wdf['Agg_Level_2'] + '_validation'\n",
        "    wdf = wdf[['id', 'scale', 'weight', 'scaled_weight']]\n",
        "    wdf = pd.merge(df[['id']], wdf, on='id', how='left')\n",
        "    \n",
        "    return wdf\n",
        "\n",
        "P_HORIZON = 28         # Prediction horizon \n",
        "NUM_PRODUCTS = 30490      # Number of products \n",
        "\n",
        "END_TEST = 1913\n",
        "train_mask = sale['d'].apply(lambda x:x[2:])<=(END_TEST-28)\n",
        "test_mask = sale['d'].apply(lambda x:x[2:])>(END_TEST-28)\n",
        "train_valid_mask = train_mask & (sale['d'].apply(lambda x:x[2:])>(END_TEST-56))\n",
        "\n",
        "wdf = get_weights_scales_level_12(sale, END_TEST, path)\n",
        "scale = wdf[train_valid_mask].scale\n",
        "weight = wdf[train_valid_mask].weight[:NUM_PRODUCTS]\n",
        "\n",
        "################### Custom metric #####################\n",
        "def custom_metric(preds, train_data):\n",
        "    actuals = train_data.get_label()\n",
        "    res = L12_WRMSSE(preds, actuals, P_HORIZON, NUM_PRODUCTS, scale, weight)\n",
        "    return 'L12_WRMSSE', res, False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jF5cxEFv3fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 清洗数据\n",
        "sale.dropna(inplace=True)\n",
        "cat_feats = ['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id'] + [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]+[\"price_digit\"]\n",
        "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
        "train_cols = sale.columns[~sale.columns.isin(useless_cols)]\n",
        "X_train = sale[train_cols]\n",
        "y_train = sale[\"sales\"]\n",
        "X_train.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCZFaPjdwE5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = lgb.Dataset(X_train, label = y_train, categorical_feature=cat_feats, free_raw_data=False)\n",
        "valid_data = lgb.Dataset(X_train.iloc[valid_inds], label = y_train.iloc[valid_inds],categorical_feature=cat_feats, free_raw_data=False)\n",
        "valid_inds = np.random.choice(len(X_train), 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM-xxSz_wKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练lgb\n",
        "t0 = time.time()\n",
        "params = {\n",
        "      \"objective\" : \"tweedie\",\n",
        "      \"tweedie_variance_power\" : 1.18,\n",
        "      \"metric\" :\"rmse\",\n",
        "      \"boosting_type\": 'gbdt',\n",
        "      \"force_row_wise\" : True,\n",
        "      \"learning_rate\" : 0.075,\n",
        "      \"sub_feature\" : 0.8,\n",
        "      \"sub_row\" : 0.75,\n",
        "      \"bagging_freq\" : 1,\n",
        "      \"lambda_l2\" : 0.1,\n",
        "      \"nthread\": -1,\n",
        "      \"verbosity\": 1,\n",
        "      \"num_iterations\" : 5000,\n",
        "      \"early_stopping_round\" : 300,\n",
        "      \"num_leaves\": 127,\n",
        "      \"min_data_in_leaf\": 104,\n",
        "      }\n",
        "evals_result = {}\n",
        "\n",
        "# m_lgb = lgb.train(params, train_data, valid_sets = [valid_data], evals_result=evals_result, feval=custom_metric, verbose_eval=25)\n",
        "m_lgb = lgb.train(params, train_data, valid_sets = [valid_data], evals_result=evals_result, verbose_eval=25)\n",
        "t1 = time.time()\n",
        "print(\"Training time: \")\n",
        "print(t1-t0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smmjPg49xezA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create test data_test_data \n",
        "train_start = 1\n",
        "test_start = 1800\n",
        "is_train = False\n",
        "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float16\" }\n",
        "CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
        "      \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int8\",\n",
        "      \"month\": \"int8\", \"year\": \"int16\", \"snap_CA\": \"int8\", 'snap_TX': 'int8', 'snap_WI': 'int8' }\n",
        "\n",
        "start_day = train_start if is_train else test_start\n",
        "numcols = [f\"d_{day}\" for day in range(start_day,1914)]\n",
        "catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
        "SALE_DTYPES = {numcol:\"float32\" for numcol in numcols} \n",
        "SALE_DTYPES.update({col: \"category\" for col in catcols if col != \"id\"})\n",
        "\n",
        "price = pd.read_csv('sell_prices.csv',dtype=PRICE_DTYPES)\n",
        "cal = pd.read_csv('calendar.csv',dtype=CAL_DTYPES)\n",
        "test_data = pd.read_csv('sales_train_validation.csv',dtype=SALE_DTYPES,usecols=catcols+numcols) #usecols读取指定列\n",
        "    \n",
        "# 类别标签转换\n",
        "for col, col_dtype in PRICE_DTYPES.items():\n",
        "  if col_dtype == \"category\":\n",
        "    price[col] = price[col].cat.codes.astype(\"int16\")\n",
        "    price[col] -= price[col].min()\n",
        "\n",
        "cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
        "for col, col_dtype in CAL_DTYPES.items():\n",
        "  if col_dtype == \"category\":\n",
        "    cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
        "    cal[col] -= cal[col].min()\n",
        "\n",
        "for col in catcols:\n",
        "  if col != \"id\":\n",
        "    test_data[col] = test_data[col].cat.codes.astype(\"int16\")\n",
        "    test_data[col] -= test_data[col].min()\n",
        "\n",
        "# 提交格式里有一部分为空\n",
        "if not is_train:\n",
        "  for day in range(1913+1, 1913+ 2*28 +1):\n",
        "    test_data[f\"d_{day}\"] = np.nan\n",
        "\n",
        "test_data = pd.melt(test_data,\n",
        "        id_vars = catcols,\n",
        "        value_vars = [col for col in test_data.columns if col.startswith(\"d_\")],\n",
        "        var_name = \"d\",\n",
        "        value_name = \"sales\")\n",
        "test_data = reduce_mem_usage(test_data)\n",
        "test_data = test_data.merge(cal, on= \"d\", copy = False)\n",
        "test_data = test_data.merge(price, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jN1QnOLxueD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 加入趋势alpha\n",
        "date = datetime(2016, 4, 25) \n",
        "alpha = [1.035]\n",
        "weights = [1/len(alphas)]*len(alphas)\n",
        "sub = 0.\n",
        "\n",
        "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
        "  test_data_c = test_data.copy()\n",
        "  cols = [f\"F{i}\" for i in range(1,29)]\n",
        "  for i in range(0, 28):\n",
        "    day = date + timedelta(days=i)\n",
        "    print(i, day)\n",
        "    tst = test_data_c[(test_data_c.date >= day - timedelta(days=57)) & (test_data_c.date <= day)].copy()\n",
        "    tst = create_feature(tst, is_train=False, day=day)\n",
        "    tst = tst.loc[tst.date == day , train_cols]\n",
        "\n",
        "    test_data_c.loc[test_data_c.date == day, \"sales\"] = alpha*m_lgb.predict(tst)\n",
        "\n",
        "  # 提交数据的格式\n",
        "  test_sub = test_data_c.loc[test_data_c.date >= date, [\"id\", \"sales\"]].copy()\n",
        "  test_sub[\"F\"] = [f\"F{rank}\" for rank in test_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
        "  test_sub = test_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
        "  test_sub.fillna(0., inplace = True)\n",
        "  test_sub.sort_values(\"id\", inplace = True)\n",
        "  test_sub.reset_index(drop=True, inplace = True)\n",
        "  if icount == 0 :\n",
        "    sub = test_sub\n",
        "    sub[cols] *= weight\n",
        "  else:\n",
        "    sub[cols] += test_sub[cols]*weight\n",
        "  print(icount, alpha, weight)\n",
        "    \n",
        "sub2 = sub.copy()\n",
        "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
        "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
        "sub.head()\n",
        "# sub.to_csv(\"LGB_v1.0.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}